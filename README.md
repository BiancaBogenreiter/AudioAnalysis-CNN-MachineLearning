# AudioAnalysis-CNN-MachineLearning

I developed a machine learning model to recognize time signatures in music, specifically 2/4, 3/4, and 4/4 beats. 
The central task involved designing and implementing a convolutional neural network (CNN) to classify time signatures based on audio features extracted from a dataset of musical tracks.

**Key Components:**
+ *train_model.py*: Responsible for training the model, this module handles data preprocessing, feature extraction, and optimization of model parameters to achieve high accuracy.
+ *test_model.py*: Focused on evaluating the modelâ€™s performance, this module tests the model on unseen data to ensure it generalizes well and maintains accuracy.
+ *musical data*: Songs sorted into folders by time signature used to train the model.

**Audio Pipeline:**
Visualization of the Audio Pipeline:
![AudioPipeline](https://github.com/user-attachments/assets/e57e8b7f-7c9c-4272-8c35-416c96478bf5)

**Key Sources**
As key resources for processing audio and integrating it with machine learning, the following websites were utilized:
+ [Paperspace: Audio Classification with Deep Learning](https://blog.paperspace.com/audio-classification-with-deep-learning/)
+ [Kaggle: Z by HP Unlocked Challenge 3 - Signal Processing](https://www.kaggle.com/datasets/kenjee/z-by-hp-unlocked-challenge-3-signal-processing/code)
